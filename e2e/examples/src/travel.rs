use carve_agentos::contracts::plugin::AgentPlugin;
use carve_agentos::contracts::tool::Tool;
use carve_agentos::extensions::observability::{
    AgentMetrics, GenAISpan, LLMMetryPlugin, MetricsSink, ToolSpan,
};
use carve_agentos::extensions::permission::PermissionPlugin;
use carve_agentos::orchestrator::AgentDefinition;
use clap::Parser;
use std::sync::Arc;
use uncarve_examples::travel::tools::*;

/// Logging sink that prints metrics to stderr after each session.
struct LoggingSink;

impl MetricsSink for LoggingSink {
    fn on_inference(&self, span: &GenAISpan) {
        eprintln!(
            "[llmmetry] inference: model={} provider={} input={:?} output={:?} cache_read={:?} cache_create={:?} {}ms",
            span.model, span.provider,
            span.input_tokens, span.output_tokens,
            span.cache_read_input_tokens, span.cache_creation_input_tokens,
            span.duration_ms,
        );
    }

    fn on_tool(&self, span: &ToolSpan) {
        eprintln!(
            "[llmmetry] tool: name={} error={:?} {}ms",
            span.name, span.error_type, span.duration_ms,
        );
    }

    fn on_run_end(&self, metrics: &AgentMetrics) {
        eprintln!(
            "\n=== Session Metrics ({:.1}s) ===",
            metrics.session_duration_ms as f64 / 1000.0
        );
        for stat in metrics.stats_by_model() {
            eprintln!(
                "  [{}@{}] {} inferences | input: {} output: {} cache_read: {} cache_create: {} | {:.1}s",
                stat.model, stat.provider, stat.inference_count,
                stat.input_tokens, stat.output_tokens,
                stat.cache_read_input_tokens, stat.cache_creation_input_tokens,
                stat.total_duration_ms as f64 / 1000.0,
            );
        }
        for stat in metrics.stats_by_tool() {
            eprintln!(
                "  [tool:{}] {} calls ({} failures) | {:.1}s",
                stat.name,
                stat.call_count,
                stat.failure_count,
                stat.total_duration_ms as f64 / 1000.0,
            );
        }
        eprintln!(
            "  totals: {} input + {} output = {} tokens | inference {:.1}s tool {:.1}s",
            metrics.total_input_tokens(),
            metrics.total_output_tokens(),
            metrics.total_tokens(),
            metrics.total_inference_duration_ms() as f64 / 1000.0,
            metrics.total_tool_duration_ms() as f64 / 1000.0,
        );
        eprintln!("===\n");
    }
}

#[tokio::main]
async fn main() {
    let args = uncarve_examples::Args::parse();

    let agent_def = AgentDefinition {
        id: "travel".into(),
        model: "deepseek-chat".into(),
        system_prompt: concat!(
            "You are a travel planning assistant. Help users plan trips by adding, ",
            "updating, and searching for places of interest. Use the provided tools ",
            "to manage trips and find destinations.\n\n",
            "When the user asks to plan a trip, create it with add_trips, then ",
            "search_for_places to find interesting locations. Always select the ",
            "active trip with select_trip after creating it."
        )
        .into(),
        max_rounds: 10,
        parallel_tools: true,
        plugin_ids: vec!["permission".into(), "llmmetry".into()],
        ..Default::default()
    };

    let tools: Vec<Arc<dyn Tool>> = vec![
        Arc::new(AddTripTool),
        Arc::new(UpdateTripTool),
        Arc::new(DeleteTripTool),
        Arc::new(SelectTripTool),
        Arc::new(SearchPlacesTool),
    ];

    let llmmetry = LLMMetryPlugin::new(LoggingSink)
        .with_model("deepseek-chat")
        .with_provider("deepseek");

    let plugins: Vec<(String, Arc<dyn AgentPlugin>)> = vec![
        ("permission".into(), Arc::new(PermissionPlugin)),
        ("llmmetry".into(), Arc::new(llmmetry)),
    ];

    uncarve_examples::serve(args, agent_def, tools, plugins).await;
}
